{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fafd2a6",
   "metadata": {},
   "source": [
    "## 1. 사이킷런 소개와 특징\n",
    "\n",
    "`사이킷런(Scikit-learn)`은 가장 많이 사용되는 파이썬 머신 러닝 라이브러리입니다. 이 책은 사이킷런을 기반으로 하여  다양한 머신 러닝 모델을 작성하는 것을 가르치고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7077d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c817ae5",
   "metadata": {},
   "source": [
    "## 2. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기\n",
    "\n",
    "사이킷런을 통해 첫 번째로 만들어볼 머신러닝 모델은 붓꽃 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처를 기반으로 꽃의 품종을 예측하는 분류 모델 입니다.\n",
    "\n",
    "우선 필요한 모듈들을 임포트합니다. `sklearn.datasets` 내의 모듈은 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임이며, `sklearn.tree` 내의 모듈은 트리 기반 ML 알고리즘을 구현한 클래스 모임, `sklearn.model_selection`은 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 모듈의 모임입니다. 붓꽃 데이터 세트를 생성하고 학습 데이터와 테스트 데이터로 분리하고 의사 결정트리를 사용하기 위해 다음과 같이 필요한 모듈을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d773515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c56956",
   "metadata": {},
   "source": [
    "`load_iris()` 함수를 통해 붓꽃 데이터 세트를 로딩한 후 `DataFrame` 으로 변환하여 데이터를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c879851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 분석을 위해 pandas 사용\n",
    "import pandas as pd\n",
    "\n",
    "#붓꽃 데이터셋 로딩\n",
    "iris=load_iris()\n",
    "\n",
    "#피쳐 데이터와 레이블 데이터를 서로 분리\n",
    "iris_data=iris.data\n",
    "iris_label=iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "#붓꽃 데이터 세트를 DataFrame 으로 변환하여 분석\n",
    "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009801c",
   "metadata": {},
   "source": [
    "\n",
    "피처에는 `sepal length`, `sepal width`, `petal length`, `petal width`의 4 종류가 있으며, 레이블 데이터는 `setosa`, `versicolor`, `virginica` 의 세 가지로 각각 0, 1, 2 의 값으로 저장이 되어 있습니다.\n",
    "\n",
    "다음으로 할 일은 붓꽃 데이터 세트를 학습용 데이터와 테스트용 데이터로 분리하는 일입니다. 테스트용 데이터를 통해 학습 데이터를 이용해 학습된 모델이 얼마나 뛰어난 성능을 가지는지 평가하기 위해서입니다.\n",
    "이를 위해 `train_test_split()` 함수를 이용하며, 파라미터로 피처 데이터 세트와 레이블 데이터 세트, 테스트 데이터 세트의 비율, 난수 발생 값을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be431ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b76b6",
   "metadata": {},
   "source": [
    "확보한 데이터를 바탕으로 머신러닝 분류 알고리즘 주 하나인 의사 결정 트리를 이용해 학습과 예측을 수행해 보겠습니다. 사이킷런에서 머신러닝 알고리즘을 사용할 때에는 알고리즘에 따라 객체를 생성한 뒤, 객체의 `fit` 매서드에 학습용 피처 데이터 세트와 레이블 데이터 세트를 입력하여 호출하여 학습을 진행시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d41c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DecisionTreeClassifier 객체 생성\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "#학습 수행\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07786563",
   "metadata": {},
   "source": [
    "학습된 모델을 기반으로 예측을 수행하기 위해서는 `predict` 메서드에 피처 데이터 세트를 입력해 호출하면 학습된 모델 기반에서 피처 데이터 세트에 대한 레이블 예측값을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3971042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c0201",
   "metadata": {},
   "source": [
    "예축 결과를 기반으로 의사 결정 트리의 예측 성능을 평가해 봅시다. `sklearn.datasets` 내의 모듈은 모델의 성능을 측정하는 모듈들의 모임입니다. 이중 `accuracy_score()` 를 이용하여 정확도를 측정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b89acbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61062d0d",
   "metadata": {},
   "source": [
    "실제 테스트 레이블 데이터 세트와 예측값을 비교한 결과 정확도 0.9333을 확인 할 수 있습니다.\n",
    "\n",
    "수행한 분류 예측 프로세스를 정리하면 다음과 같습니다.\n",
    "\n",
    "> 1. 데이터 세트 분리: 데이터를 학습 데이터와 테스트 데이터로 분리합니다.\n",
    "> 2. 모델 학습: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킵니다.\n",
    "> 3. 예측 수행: 학습된 ML 모델을 이용해 테스트 데이터의 분류를 예측합니다.\n",
    "> 4. 평가: 이렇게 예측된 결과값과 테스트 데이터의 실제 결과값을 비교해 ML 모델 성능을 평가합니다.\n",
    "\n",
    "## 3.사이킷런의 기반 프레임워크 익히기\n",
    "\n",
    "### 3.1. Estiamtor 이해 및 fit(), predict() 메서드\n",
    "\n",
    "사이킷런은 지도학습의 주요 두 축인 분류와 회귀의 다양한 알고리즘을 클래스로 구현하여 사용하기 쉽게 합니다. 분류 알고리즘을 구현한 클래스는 `Classifier`, 회귀 알고리즘을 구현한 클래스는 `Regressor`로 지칭하며, 이들을 합쳐 `Estimator` 클래스라고 부릅니다. 이들은 `fit()` 과 `predict()` 매서드를 통해 간단하게 학습과 예측을 합니다. `cross_val_score` 와 같은 평가 함수나, `GridSearchCV`와 같은 하이퍼 파라미터 튜닝을 지원하는 클래스는 이 `Estimator` 클래스를 인자로 받아 주어진 역할을 수행합니다.\n",
    "\n",
    "사이킷런은 비지도학습인 차원 축소, 클러스터링, 피처 추출 등도 클래스로 구현하여 사용하기 쉽게 합니다. 이러한 클래스는 입력 데이터의 형테에 맞춰 데이터를 변환하기 위한 사전 구조 작업인 `fit()` 과, 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등 작업을 수행하는 `transform()` 매서드를 사용해 비지도학습을 쉽게 수행할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62880ab7",
   "metadata": {},
   "source": [
    "### 3.2. 사이킷런의 주요 모듈\n",
    "\n",
    "| 분류                              | 모듈명                       | 설명                                                                      |\n",
    "| --------------------------------- | ---------------------------- | ------------------------------------------------------------------------- |\n",
    "| 예제 데이터                       | `sklearn.datasets`           | 예제 데이터세트                                                           |\n",
    "| 피처 처리                         | `sklearn.preprocessing`      | 데이터 전처리에 필요한 가공 기능                                          |\n",
    "| 피처 처리                         | `sklearn.feature_selection`  | 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 선택                      |\n",
    "| 피처 처리                         | `sklearn.feature_extraction` | 텍스트 데이터나 이미지 데이터의 벡터화된 피처 추출                        |\n",
    "| 피처 처리 & 차원 축소             | `sklearn.decomposition`      | 차원 축소와 관련된 알고리즘                                               |\n",
    "| 데이터 분리, 검증 & 파라미터 튜닝 | `sklearn.model_selection`    | 교차 검증을 위한 학습용/테스트용 분리, 그리드 서치로 최적 파라미터 추출   |\n",
    "| 평가                              | `sklearn.metrics`            | 다양한 성능 측정 방법 제공                                                |\n",
    "| ML 알고리즘                       | `sklearn.ensemble`           | 앙상블 알고리즘                                                           |\n",
    "| ML 알고리즘                       | `sklearn.linear_model`       | 선형 회귀, 릿지, 라쏘, 로지스틱 회귀 등 회귀 관련 알고리즘 제공           |\n",
    "| ML 알고리즘                       | `sklearn.naive_bayes`        | 나이브 베이즈 알고리즘                                                    |\n",
    "| ML 알고리즘                       | `sklearn.neighbors`          | 최근접 이웃 알고리즘 알고리즘                                             |\n",
    "| ML 알고리즘                       | `sklearn.svm`                | 서포트 벡터 머신 알고리즘                                                 |\n",
    "| ML 알고리즘                       | `sklearn.tree`               | 의사 결정 트리 알고리즘                                                   |\n",
    "| ML 알고리즘                       | `sklearn.cluster`            | 비지도 클러스터링 알고리즘                                                |\n",
    "| 유틸리티                          | `sklearn.pipeline`           | 피처 처리 등 변환과 ML 알고리즘 학습, 예측을 묶어 실행할 수 있는 유틸리티 |\n",
    "\n",
    "### 3.3. 사이킷런의 주요 모듈\n",
    "\n",
    "(생략)\n",
    "\n",
    "## 4. Model Selection 모듈 소개\n",
    "\n",
    "학습과 예측을 동일한 데이터 세트로 수행하게 되면, 이미 학습한 데이터 세트를 기반으로 예측하기 때문에 정확도가 100%가 나오는 문제가 발생합니다. 이러한 문제를 해결하기 위해 사이킷런의 `train_test_split()` 을 통해 원본 데이터 세트에서 학습 및 테스트 데이터 세트를 쉽게 분리할 수 있습니다. 파라미터로 피처 데이터 세트와 레이블 데이터 세트를 입력받습니다. 선택적으로, 테스트 데이터 세트의 비율, 데이터를 섞을지, 난수 발생 값을 사용합니다. 다음 예제를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12cc103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred= dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3874ee",
   "metadata": {},
   "source": [
    "전체 데이터 세트의 30%를 테스트 데이터로, 70%를 학습 데이터로 분리한 뒤 학습시킨 모델의 예측 정확도를 확인할 수 있습니다.\n",
    "\n",
    "### 4.2. 교차 검증\n",
    "\n",
    "모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 경우 예측 성능이 과도하게 떨어지는 과적합 현상을 막기 위해, 여러 개의 학습 데이터 세트와 테스트 데이터 세트에 대해 학습과 평가를 수행하는 교차 검증이 효율적일 수 있습니다.\n",
    "\n",
    "#### 4.3.1. K 폴드 교차 검증\n",
    "\n",
    "K폴드 교차 검증은 전체 데이터 세트를 K개의 데이터 폴드 세트로 만든 다음, 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법입니다.\n",
    "\n",
    "예를 들어, k=5 일때는 데이터 세트를 5개로 나눈 뒤 그 중 1개를 검증, 나머지 4개를 학습에 사용하는 것을 5회 반복한 후 각 결과를 평균 내어 평가 결과로 반영하면 됩니다. \n",
    "\n",
    "사이킷런의 KFold 클래스를 이용해 교차 검증을 쉽게 할 수 있습니다. 다음 예시를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f856380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter=0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 변환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    \n",
    "    #kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    #정확도 측정\n",
    "    accuracy=np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "#평균 정확도 계산    \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd26692",
   "metadata": {},
   "source": [
    "전체 데이터 세트 150 개를 5등분 하였으므로 120개의 학습 데이터와 30개의 검증 데이터로 학습과 검증이 진행되는 것을 확인할 수 있습니다. 학습 데이터와 검증 데이터가 변하기 때문에 매번 검증 정확도가 달라지며, 교차 검증 정확도의 평균으로 전체 정확도를 측정할 수 있습니다.\n",
    "\n",
    "#### 4.3.2. Stratified K 폴드\n",
    "\n",
    "Stratified K 폴드는 특정 레이블 값이 특이하게 많거나 매우 적어 값의 분포가 한쪽으로 치우치는 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식입니다. Stratified K 폴드는 원본 데이터의 레이블 분포를 먼저 고려한 뒤, 이 분포와 동일하게 학습과 검증 데이터 세트를 분배합니다.\n",
    "\n",
    "우선 붓꽃 데이터 세트에서 레이블 값의 분포도를 확인합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71fd7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbe0c6",
   "metadata": {},
   "source": [
    "확인 결과 레이블 값은 0, 1, 2 모두 50개로 동일합니다. `StratifiedKFold` 를 수행하고 각 교차 검증에서 학습과 검증 레이블데이터의 분포를 살펴보겠습니다. 이때 주의하여야 할 점은 `StratifiedKFold` 를 사용할 때는 `split()` 매서드의 인자로 피처 데이터 세트 뿐만 아니라 레이블 데이터 세트도 반드시 필요하다는 사실입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca740659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbd28e",
   "metadata": {},
   "source": [
    "`StratifiedKFold` 를 사용하면 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당되었음을 확인할 수 있습니다. 이를 활용하여 붓꽃 데이터를 교차 검증하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6baceaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    accuracy=np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa28b4",
   "metadata": {},
   "source": [
    "3 개의 `Stratified K 폴드`로 교차 검증한 결과 평균 검증 정확도가 96.7% 정도임을 확인할 수 있습니다. 왜곡된 레이블 데이터 세트에서는 반드시 `Stratified K 폴드`를 이용해 교차 검증해야 합니다.\n",
    "\n",
    "#### 4.3.3. 교차 검증을 보다 간편하게- cross_val_score()\n",
    "\n",
    "사이킷런은 교차 검증을 좀 더 편리하게 수행할 수 있는 `cross_val_score()` API 를 제공합니다. 다음과 같은 형태로 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c06d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d3caa",
   "metadata": {},
   "source": [
    "이중 주요 파라미터는 `estimator`, `X`, `y`, `scoring`, `cv` 입니다. `estimator`는 사이킷런의 분류 또는 회귀 알고리즘 클래스를 의미하며,  `X`는 피처 데이터 세트, `y`는 레이블 데이터 세트, `scoring`은 예측 성능 평가 지표, `cv`는 교차 검증 폴드 수를 의미합니다. `cross_val_score()`는 실행되면 `Stratified K 폴드` 방식으로 진행한 교차 검증의 `scoring` 파라미터 성능 지표 값을 배열로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4276734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data=load_iris()\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data=iris_data.data\n",
    "label=iris_data.target\n",
    "\n",
    "scores=cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
    "print('교차 검증별 정확도:', np.round(scores,4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc3ac6",
   "metadata": {},
   "source": [
    "주어진 파라미터에 따라 3개의 교차 검증 세트로 측정한 정확도를 확인할 수 있습니다. 비슷한 API로, 여러 평가 지표에 대한 성능을 확인하고 싶을 때에는 `cross_validate()` 를 사용하면 됩니다.\n",
    "\n",
    "#### 4.3.4. GridSearchCV - 교차 검증과 하이퍼 파라미터 튜닝을 한 번에\n",
    "\n",
    "하이퍼 파라미터는 머신 러닝 알고리즘을 구성하는 주요 요소로, 이 값을 조정하여 예측 성능을 개선시킬 수 있습니다. 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터 조합을 찾고자 한다면 해당 파라미터의 집합을 딕셔너리의 형태로 설정하고 `GridSearchCV` 를 사용한다면 최적의 파라미터와 수행 결과를 찾을 수 있습니다. `GridSearchCV`의 주요 파라미터는 `estimator`, 튜닝할 파라미터의 딕셔너리인 `param_grid`, `scoring`, 교차 검증 세트의 개수인 `cv`, 최적 학습 파라미터로 `estimator` 객체를 재학습시킬지의 유무를 결정하는 `refit` 이 있습니다. 다음 예시를 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b78bac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "#데이터를 로딩하고 학습과 테스트 데이터 분리\n",
    "iris_data=load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "#튜닝할 파라미터를 딕셔너리의 형태로 결정\n",
    "parameters={'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
    "\n",
    "grid_dtree=GridSearchCV(dtree,param_grid=parameters, cv=3, refit=True)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f359bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCv 최적 정확도:0.9750\n",
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:',grid_dtree.best_params_)\n",
    "print('GridSearchCv 최적 정확도:{0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "estimator=grid_dtree.best_estimator_\n",
    "\n",
    "pred=estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a9951",
   "metadata": {},
   "source": [
    "## 5. 데이터 전처리\n",
    "\n",
    "데이터 전처리 과정은 ML 알고리즘만큼 중요합니다. 사이킷런의 ML 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야할 사항이 있습니다. 우선 결손값 NaN과 Null 은 허용되지 않기 때문에 적당한 값으로 대체되거나 피처가 제거되어야 하며, 사이킷런의 머신러닝 알고리즘은 문자열 값을 입력 값으로 허용하지 않기 때문에 인코딩돼서 숫자 형으로 변환되어야 합니다.\n",
    "\n",
    "### 5.1. 데이터 인코딩\n",
    "\n",
    "#### 5.1.1. 레이블 인코딩\n",
    "레이블 인코딩은 카테고리 피처를 코드형 숫자 값으로 변환하는 것입니다. 예를 들어 상품 구분 'TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '믹서' 가 있다면, TV:1, 냉장고:2, 전자레인지:3, 컴퓨터:4, 선풍기:5, 믹서:6 과 같은숫자 값으로 변환하는 것입니다. 이는 사이킷런의 `LabelEncoder` 클래스를 이용해 쉽게 구현이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb02991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n",
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본값: ['TV' '냉장고' '전자레인지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값:', labels)\n",
    "print('인코딩 클래스:',encoder.classes_)\n",
    "print('디코딩 원본값:',encoder.inverse_transform(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e20e1a",
   "metadata": {},
   "source": [
    "`fit()` 매서드를 호출해 레이블 인코딩을 수행할 수 있습니다. `classes_` 속성에 0번부터 순서대로 변환된 인코딩 값에 대한 원본값을 가지고 있으며, `inverse_transform()`을 통해 인코딩된 값을 다시 디코딩할 수 있습니다.\n",
    "\n",
    "레이블 인코딩은 문자열 값이 숫자형 카테고리 값으로 변환되면서 숫자 값의 크고 작음에 대한 특성이 작용하기 때문에 특정 ML 알고리즘에서 예측 성능이 떨어지는 문제가 발생할 수 있습니다. 이러한 특성 때문에 레이블 인코딩은 선형 회귀와 같은 ML 알고리즘에는 적영되지 않아야 합니다. 트리 계열의 ML 알고리즘은 숫자의 크고 작음 특성을 반영하지 않으므로 레이블 인코딩이 사용되어도 됩니다.\n",
    "\n",
    "#### 5.1.2. 원-핫 인코딩 (One-Hot Encoding)\n",
    "\n",
    "원-핫 인코딩은 피처 값의 유형에 따라 새로운 피처를 추가하고 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 말럼은 0을 표시하는 방식입니다. 예를 들어, 위의 예시에서 'TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '믹서' 라는 칼럼을 모두 만들어준 후, TV 인 경우에는 TV 칼럼에 1을, 나머지 칼럼에는 0을 표시하는 방식입니다. 이는 사이킷런의 `OneHotEncoder` 클래스를 이용해 쉽게 구현이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467525c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "#먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "#2차원 데이터로 변환\n",
    "labels = labels.reshape(-1,1)\n",
    "\n",
    "#원-핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels=oh_encoder.transform(labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41ea53",
   "metadata": {},
   "source": [
    "8개의 레코드를 가진 원본 데이터와 8개의 레코드와 상품의 종류 수인 6개의 칼럼을 가진 데이터로 변환된 것을 확인할 수 있습니다.\n",
    "\n",
    "판다스에는 원-핫 코딩을 더 쉽게 지원하는 `get_dummies()` 를 사용할 수 있습니다. 이는 `OneHotEncoder()`와는 다르게 문자열 카테고리 값을 바로 변환할 수 있다는 장점을 갖습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c0afc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({'item' : ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de003b",
   "metadata": {},
   "source": [
    "### 5.2. 피처 스케일링과 정규화\n",
    "\n",
    "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 피처 스케일링(feature scaling)이라고 합니다. 대표적인 방법으로는 표준화(Standardization)와 정규화(Normalization)가 있습니다.\n",
    "\n",
    "표준화는 데이터의 피처 각각이 평균이 0이고, 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것을 의미합니다. 다음과 같은 수식으로 변환이 이루어집니다.\n",
    "$$ x_i\\;new= \\frac{ x_i - mean(x)}{ stdev(x) } $$\n",
    "\n",
    "정규화는 서로 다른 피처의 크기를 통일하기 위해 크기를 최소 0 ~ 최대 1의 값으로 변환하는 것입니다. 다음과 같은 수식으로 변환이 이루어집니다.\n",
    "$$ x_i\\;new= \\frac{ x_i - min(x)}{ max(x) - min(x) } $$\n",
    "\n",
    "벡터 정규화는 선형대수에서의 정규화 개념이 적용되어 개별 벡터를 모든 피처 벡터의 크기로 나눠주는 변환입니다. 세 개의 피처 x, y, z가 있다면 다음과 같은 수식으로 변환이 이루어집니다.\n",
    "$$ x_i\\;new= \\frac{ x_i }{ \\sqrt{x^2_i + y^2_i + z^2_i} } $$\n",
    "\n",
    "### 5.3. StandardScaler\n",
    "\n",
    "`StandardScaler`는 표준화를 쉽게 지원하기 위한 클래스입니다. 데이터 세트를 통해 `StandardScaler`가 어떻게 데이터 값을 변환하는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62061695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n",
      "\n",
      "feature들의 평균값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "#기존 데이터\n",
    "print('feature들의 평균값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature들의 분산값')\n",
    "print(iris_df.var())\n",
    "\n",
    "#데이터 표준화\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "#표준화된 데이터\n",
    "#기존 데이터\n",
    "print('\\nfeature들의 평균값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature들의 분산값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b61b3f",
   "metadata": {},
   "source": [
    "모든 칼럼의 평균이 0에, 분산은 1에 가깝게 변환된 것을 확인할 수 있습니다.\n",
    "\n",
    "### 5.4. MinMaxScaler\n",
    "\n",
    "`MinMaxScaler`는 정규화를 쉽게 지원하기 위한 클래스입니다. 데이터 세트를 통해 `MinMaxScaler`가 어떻게 데이터 값을 변환하는지 확인해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b68dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최소값\n",
      "sepal length (cm)    4.3\n",
      "sepal width (cm)     2.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     0.1\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최대값\n",
      "sepal length (cm)    7.9\n",
      "sepal width (cm)     4.4\n",
      "petal length (cm)    6.9\n",
      "petal width (cm)     2.5\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "#기존 데이터\n",
    "print('feature들의 최소값')\n",
    "print(iris_df.min())\n",
    "print('\\nfeature들의 최대값')\n",
    "print(iris_df.max())\n",
    "\n",
    "#데이터 표준화\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "#표준화된 데이터\n",
    "#기존 데이터\n",
    "print('\\nfeature들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a50dc",
   "metadata": {},
   "source": [
    "모든 피처에 0에서 1 사이의 값으로 변환되는 스케일링이 적용되었음을 알 수 있습니다.\n",
    "\n",
    "### 5.5. 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
    "\n",
    "`Scaler`객체를 이용해 학습 데이터 세트로 `fit()` 과 `transform()`을 적용하면 테스트 데이터 세트로는 다시 `fit()`을 수행하지 않고 학습 데이터 세트로 `fit()`을 수행한 결과를 이용해 `transform()`변환을 적용해야 합니다. 테스트 데이터로 다시 스케일링 기준 정보를 만들게 되면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 서로 달라져 올바른 예측 결과를 도출하지 못할 수 있습니다.\n",
    "\n",
    "가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리하여야 하며, 그것이 여의치 않다면 학습 데이터로 이미 `fit()`된 `Scaler`객체를 이용해 테스트 데이터에 `transform()`을 적용해 주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61083a",
   "metadata": {},
   "source": [
    "## 6. 사이킷런으로 수행하는 타이타닉 생존자 예측\n",
    "\n",
    "Kaggle의 타이타닉 탑승자 데이터를 이용하여 사이컷런을 활용해 생존자 예측을 수행해 보겠습니다.\n",
    "[데이터셋 출처](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "우선 데이터를 불러와 구조를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd759d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df=pd.read_csv('./train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76e905",
   "metadata": {},
   "source": [
    "로딩된 데이터 칼럼 타입을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51215c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### 학습 데이터 정보 ### \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ### 학습 데이터 정보 ### \\n\")\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b77357",
   "metadata": {},
   "source": [
    "데이터셋은 891개의 로우, 12개의 칼럼으로 구성되어 있고, 각 칼럼의 데이터 타입도 확인할 수 있습니다.\n",
    "\n",
    "`Age`, `Cabin`, `Embarked` 칼럼의 Non-Null Count가 칼럼의 수와 다른 것으로 보아 이 세 칼럼은 결측치가 존재합니다.\n",
    "`Age` 칼럼은 평균값으로, `Cabin`과 `Embarked` 칼럼은 `N` 으로 결측치를 대체하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79466efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N',inplace=True)\n",
    "titanic_df['Embarked'].fillna('N',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869201e",
   "metadata": {},
   "source": [
    "다음으로 남아있는 문자열 피처 `Sex`, `Cabin`, `Embarked`의 값 분류를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a24da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sex 값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 :\n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 :\n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(' Sex 값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 :\\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 :\\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fd107",
   "metadata": {},
   "source": [
    "`Cabin`칼럼의 값들이 제대로 정리되지 않았다는 사실을 확인할 수 있습니다. 이를 정리하기 위해 `Cabin`속성의 앞 문자만 추출하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a82680",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Cabin']=titanic_df['Cabin'].str[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f9028",
   "metadata": {},
   "source": [
    "머신러닝 알고리즘을 적용해 예측을 수행하기 전에 데이터 탐색을 진행해 보겠습니다. 성별, 객실 등급, 나이에 따른 생존 확률을 `seaborn`을 활용해 시각화하여 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb0990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex','Survived'])['Survived'].count()\n",
    "sns.barplot(x='Sex',y='Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba173c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass',y='Survived',hue='Sex',data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0354046f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_category(age):\n",
    "    cat=''\n",
    "    if(age<=-1):\n",
    "        cat='Unknown'\n",
    "    elif (age<=5):\n",
    "        cat='Baby'\n",
    "    elif (age<=12):\n",
    "        cat='Child'\n",
    "    elif (age<=18):\n",
    "        cat='Teenager'\n",
    "    elif (age<=25):\n",
    "        cat='Student'\n",
    "    elif (age<=35):\n",
    "        cat='Young Adult'\n",
    "    elif (age<=60):\n",
    "        cat= 'Adult'\n",
    "    else:\n",
    "        cat='Elderly'\n",
    "    \n",
    "    return cat;\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "group_names=['Unknown','Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "titanic_df['Age_cat']= titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43af6ea",
   "metadata": {},
   "source": [
    "여성이 남성에 비해 생존 확률이 높았으며, 더 높은 객실 등급의 생존 확률이 높으며, 아이와 노약자의 생존 확률이 높다는 것을 확인할 수 있습니다. 즉, `Age`, `Sex`, `PClass` 피처는 생존을 좌우하는 중요한 피처임을 알 수 있습니다.\n",
    "\n",
    "마지막으로 남아있는 문자열 카테고리 피쳐를 레이블 인코딩을 통해 숫자형으로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3299f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features=['Cabin' , 'Sex' , 'Embarked']\n",
    "    for feature in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(dataDF[feature])\n",
    "        dataDF[feature]=le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96472c5a",
   "metadata": {},
   "source": [
    "지금까지의 피처 가공을 정리하고 함수로 만들어 쉽게 재사용할 수 있도록 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43779abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 제거\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "#불필요한 피쳐 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features=['Cabin' , 'Sex' , 'Embarked']\n",
    "    for feature in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(df[feature])\n",
    "        df[feature]=le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "#위 함수들을 하나의 함수로 처리\n",
    "def transform_features(df):\n",
    "    df=fillna(df)\n",
    "    df=drop_features(df)\n",
    "    df=format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e09152",
   "metadata": {},
   "source": [
    "데이터를 불러와 피처 데이터 세트와 레이블 데이터 세트를 추출한 후, 피처를 가공하고 테스트 데이터와 학습 데이터를 추출하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5185644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 데이터 불러오기\n",
    "titanic_df=pd.read_csv('./train.csv')\n",
    "y_titanic_df=titanic_df['Survived']\n",
    "X_titanic_df=titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "#피처 데이터 가공\n",
    "X_titanic_df=transform_features(X_titanic_df)\n",
    "\n",
    "#학습 데이터세트와 테스트 데이터세트 추출\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19223963",
   "metadata": {},
   "source": [
    "ML 알고리즘인 결정 트리, 랜덤 포레스트, 로지스틱 회귀를 각각 적용하여 타이타닉 생존자 예측을 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2253339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정트리 정확도: 0.7877\n",
      "랜덤포레스트 정확도: 0.8547\n",
      "로지스틱 회귀 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.tree import DecisionTreeClassifier\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#사이킷런 Classifier 클래스 생성\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)\n",
    "rf_clf=RandomForestClassifier(random_state=11)\n",
    "lr_clf=LogisticRegression()\n",
    "\n",
    "# 결정 트리 학습/예측/평가\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred=dt_clf.predict(X_test)\n",
    "print('결정트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# 랜덤 포레스트 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred=rf_clf.predict(X_test)\n",
    "print('랜덤포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# 로지스틱 회귀 학습/예측/평가\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred=lr_clf.predict(X_test)\n",
    "print('로지스틱 회귀 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd7625",
   "metadata": {},
   "source": [
    "다음으로 교차 검증을 통해 정확도를 더 자세히 평가해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34b47f32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--결정트리--\n",
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n",
      "\n",
      "--랜덤 포레스트--\n",
      "교차 검증 0 정확도: 0.7933\n",
      "교차 검증 1 정확도: 0.7978\n",
      "교차 검증 2 정확도: 0.8483\n",
      "교차 검증 3 정확도: 0.7640\n",
      "교차 검증 4 정확도: 0.8652\n",
      "평균 정확도: 0.8137\n",
      "\n",
      "--로지스틱 회귀--\n",
      "교차 검증 0 정확도: 0.7989\n",
      "교차 검증 1 정확도: 0.7697\n",
      "교차 검증 2 정확도: 0.7809\n",
      "교차 검증 3 정확도: 0.7753\n",
      "교차 검증 4 정확도: 0.8090\n",
      "평균 정확도: 0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#결정트리 교차검증\n",
    "print(\"--결정트리--\")\n",
    "scores_dt = cross_val_score(dt_clf, X_titanic_df , y_titanic_df , cv=5)\n",
    "for iter_count,accuracy in enumerate(scores_dt):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores_dt)))\n",
    "\n",
    "#랜덤 포레스트 교차검증\n",
    "print(\"\\n--랜덤 포레스트--\")\n",
    "scores_rf = cross_val_score(rf_clf, X_titanic_df , y_titanic_df , cv=5)\n",
    "for iter_count,accuracy in enumerate(scores_rf):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores_rf)))\n",
    "\n",
    "#로지스틱 회귀 교차검증\n",
    "print(\"\\n--로지스틱 회귀--\")\n",
    "scores_lr = cross_val_score(lr_clf, X_titanic_df , y_titanic_df , cv=5)\n",
    "for iter_count,accuracy in enumerate(scores_lr):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores_lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d75562",
   "metadata": {},
   "source": [
    "마지막으로 `GridSearchCV`를 이용해 `DecisionTreeClassifier`의 최적 하이퍼 파라미터를 찾고 성능을 측정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea4e3cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#탐색할 파라미터\n",
    "parameters = {'max_depth':[2,3,5,10],\n",
    "             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "#최적 파라미터 탐색\n",
    "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n",
    "grid_dclf.fit(X_train , y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "#최적 파라미터로 학습된 Estimator로 예측 및 평가 수행\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d2175",
   "metadata": {},
   "source": [
    "하이퍼 파라미터 튜닝을 적용한 결과 정확도가 예측 정확도가 크게 증가한 것을 확인할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

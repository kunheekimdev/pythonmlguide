{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신 러닝 모델은 여러 가지 방법으로 예측 성능을 평가할 수 있습니다. 모델의 목적과 데이터의 종류에 따라 맞는 평가 방법을 사용하지 않는다면 잘못된 평가 결과에 빠질 수 있습니다. 이번 장에서는 분류 모델에 사용되는 성능 평가 지표인 정확도(Accuracy), 오차행렬(Confusion Matrix), 정밀도(Precision), 재현율(Recall), F1 스코어, ROC AUC 에 대해 설명합니다.\n",
    "\n",
    "## 1. 정확도 (Accuracy)\n",
    "\n",
    "정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다.\n",
    "$$ 정확도(Accuracy) = \\frac{예측\\;결과가\\;동일한\\;데이터\\;건수}{ 전체\\;예측\\;데이터\\;건수 } $$\n",
    "\n",
    "정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표입니다. 하지만 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우 적합한 평가 지표가 아닙니다. 예를 들어 100 개의 데이터가 있고 이중 90개의 데이터 레이블이 0, 단 10 개의 레이블이 1이라 한다면 무조건 0으로 예측 결과를 반환하는 ML모델의 경우라도 정확도가 90%가 됩니다.\n",
    "\n",
    "0-9까지의 숫자 이미지의 픽셀 정보 데이터 세트인 `MNIST` 데이터 세트를 이용해 실습을 해보겠습니다. `MNIST` 데이터 세트 중 레이블 값이 7 인 것만 True, 나머지를 False 로 변환해 전체 데이터의 10%만 True, 90는 False 인 불균형한 데이터 세트로 변환해 본 뒤, 모든 데이터에 대해 0을 결과값으로 반환하는 `MyFakeClassifier`를 이용해 에측과 평가를 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X ,y):\n",
    "        pass\n",
    "    \n",
    "    #입력 값으로 들어오는 X 데이터 세트의 크기 만큼 모두 0 값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "\n",
    "# MNIST 데이터 세트를 불러와서 타깃 레이블이 7 인 경우 1, 아니라면 0으로 변환\n",
    "digits= load_digits()\n",
    "y= (digits.target==7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=11)\n",
    "\n",
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# 헉숩 / 예측 / 정확도 평가\n",
    "fakeclf= MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred=fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test,fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 값을 0 으로 예측하여도 90%의 정확도가 나오는 것을 확인할 수 있습니다. 이렇게 정확도 평가 지표를 불균형한 레이블 데이터 세트에서 사용했을 때의 문제점을 해결하기 위해 여러 분류 지표를 함께 사용하여야 합니다,\n",
    "\n",
    "## 2. 오차 행렬\n",
    "\n",
    "이진 분류에서 성능 지표로 활용되는 오차 행렬 (confusion matrix, 혼동 행렬)은 학습된 분류 모델의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다. 오차 행렬은 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지를 나타냅니다. 4분면의 왼쪽, 오른쪽을 예측된 클래스 값 기준으로 Negative 와 Positive 로 분류하고, 4분면의 위, 아래를실제 클래스 값 기준으로 Negative 와 Positive로 분류하면 예측 클래스와 실제 클래스의 값 유형에 따라 결정되는 TN, FP, FN, TP 형태로 오차 행렬의 4분면을 채울 수 있습니다. \n",
    "\n",
    "> TN는 예측 값을 Negative 값 0 으로 에측했고 실제 값 역시 Negative 값 0\n",
    "\n",
    "> FP는 예측 값을 Positive 값 1 으로 에측했고 실제 값 역시 Negative 값 0\n",
    "\n",
    "> FN는 예측 값을 Negative 값 0 으로 에측했고 실제 값 역시 Positive 값 1\n",
    "\n",
    "> TP는 예측 값을 Positive 값 1 으로 에측했고 실제 값 역시 Positive 값 1\n",
    "\n",
    "사이킷런은 오차 행렬을 구하기 위해 confusion_matrix() API를 제공합니다. 앞서 정확도 에서 사용한 예제를 그대로 활용하여 오차 행렬을 출력해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력 결과 TN, FP, FN, TP의 개수를 각각 확인할 수 있습니다. 이 값들을 조합하면 여러 성능 측정 지표인 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있습니다.\n",
    "예를 들어, 정확도는 다음과 같이 계산이 가능합니다.\n",
    "\n",
    "$$ 정확도(Accuracy) = \\frac{예측\\;결과가\\;동일한\\;데이터\\;건수}{ 전체\\;예측\\;데이터\\;건수 } = \\frac{TN + TP}{ TN + FP + FN + TP }$$ \n",
    "\n",
    "## 3. 정밀도와 재현율\n",
    "\n",
    "정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표입니다. 각각 다음과 같은 공식으로 계산됩니다.\n",
    "\n",
    "$$ 정밀도(Precision) = \\frac{예측과\\;실제\\;값이\\;모두\\;Positive인\\;데이터\\;건수}{ 예측을\\; Positive로\\;한\\;데이터\\;건수 } = \\frac{TP}{ FP + TP }$$ \n",
    "$$ 재현율(Recall) = \\frac{예측과\\;실제\\;값이\\;모두\\;Positive인\\;데이터\\;건수}{ 실제\\; 값이\\; Positive인\\;데이터\\;건수 } = \\frac{TP}{ FN + TP }$$ \n",
    "\n",
    "정밀도와 재련율 지표는 분류 모델의 목적에 따라 특정 평가 지표가 더 중요한 지표로 간주될 수 있습니다. 실제 Positive인 데이터 예측을 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우에는 재현율이 상대적으로 더 중요한 지표입니다. 한편 실제 Negative인 데이터 예측을 Positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우에는 정밀도가 상대적으로 더 중요한 지표입니다. 재현율과 정밀도 모두 TP를 높이는 데 동일하게 초점을 맞추지만, 재현율은 FN을 낮추는 데, 정밀도는 FP를 낮추는 데 초점을 맞추기 때문입니다.\n",
    "\n",
    "일반적인 경우 두 지표는 서로 보완적인 지표로 분류의 성능을 평가하는 데 적용되며, 어느 한쪽만 높은 수치를 얻기보다는 둘 모두 높은 수치를 얻는 것이 좋은 평가입니다. \n",
    "\n",
    "사이킷 런의 `precision_score()` 를 사용하여 정밀도를 ,`recall_score()`를 사용하여 재현율을 계산할 수 있습니다. 타이타닉 예제에 오차 행렬 및 정밀도, 재현율을 모두 구해 예측 성능을 평가해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터셋 출처](https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "#오차 행렬, 정확도, 정밀도, 재현율을 모두 구하는 함수\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#앞 단원에서 사용한 데이터 전처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features=['Cabin' , 'Sex' , 'Embarked']\n",
    "    for feature in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(df[feature])\n",
    "        df[feature]=le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df=fillna(df)\n",
    "    df=drop_features(df)\n",
    "    df=format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.849162, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#원본 데이터 재로딩, 가공, 학습/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('./train.csv')\n",
    "y_titanic_df=titanic_df['Survived']\n",
    "X_titanic_df=titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df=transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,test_size=0.20, random_state=11)\n",
    "lr_clf=LogisticRegression()\n",
    "\n",
    "#학습 및 예측\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차 행렬과 정확도, 정밀도, 재현율 값을 확인할 수 있습니다. 재현율이 정밀도보다 높게 나왔습니다. 만약 정밀도를 좀 더 강화하고 싶다면, 어떻게 해야 할까요?\n",
    "\n",
    "### 3.1. 정밀도 - 재현율 트레이드오프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "print('pred_proba() 결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:',pred_proba[:3])\n",
    "\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pred_proba_class1=lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('반환된 분류 결정 임계값 배열의 Shape:', thresholds.shape)\n",
    "\n",
    "thr_index= np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index],2))\n",
    "\n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    \n",
    "    plt.xlabel('Threshold value')\n",
    "    plt.ylabel('Precision and Recall value')\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임계값:', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "    \n",
    "\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    \n",
    "    f1= f1_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}\\n'.format(accuracy, precision, recall, f1))\n",
    "    \n",
    "thresholds=[0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "pred_proba= lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1, 1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve & AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def roc_curve_plot(y_test, pred_proba_c1):\n",
    "\n",
    "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.plot(fprs, tprs, label='ROC')\n",
    "    \n",
    "    plt.plot([0,1],[0,1], 'k--', label='random')\n",
    "    \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('FPR(1-Sensitivity)')\n",
    "    plt.ylabel('TPR(Recall)')\n",
    "    plt.legend()\n",
    "    \n",
    "roc_curve_plot(y_test, pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "roc_score=roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피마 인디언 당뇨병 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터셋 출처](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "diabetes_data= pd.read_csv('diabetes.csv')\n",
    "print(diabetes_data['Outcome'].value_counts())\n",
    "diabetes_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_features=['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "mean_zero_features = diabetes_data[zero_features].mean()\n",
    "diabetes_data[zero_features]=diabetes_data[zero_features].replace(0, mean_zero_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 모델(로지스틱 회귀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1= f1_score(y_test, pred)\n",
    "    roc_auc= roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    \n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\ F1:{3:.4f}, AUC:{4:.4f}\\n'.format(accuracy, precision, recall, f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_data.iloc[:, :-1]\n",
    "y = diabetes_data.iloc[:, -1]\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=156, stratify=y)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred= lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_c1 = lr_clf.predict_proba(X_test)[:,1]\n",
    "precision_recall_curve_plot(y_test, pred_proba_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=0.48)\n",
    "\n",
    "pred_th_048 =binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1))\n",
    "\n",
    "get_clf_eval(y_test, pred_th_048, pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83bec100e1fa04fbae079241f253fc6c57758e7e5b0af3851790a21f420b80f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
